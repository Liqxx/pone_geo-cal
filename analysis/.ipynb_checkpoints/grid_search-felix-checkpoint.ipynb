{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icecube:\n",
    "from icecube import dataio, dataclasses, simclasses\n",
    "from icecube.icetray import OMKey\n",
    "from icecube.dataclasses import *\n",
    "\n",
    "# The usual:\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import h5py\n",
    "\n",
    "#Plotting:\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/user/fhenningsen/deepcore_data/felix_sca-domeff-11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new GCD\n",
    "geometry = dataio.I3File(\"/home/fhenningsen/gcd/physics_volume_GCD.i3.bz2\")\n",
    "\n",
    "gframe = geometry.pop_frame()  \n",
    "geo = gframe[\"I3Geometry\"] # access geo file via key\n",
    "all_dom_keys = geo.omgeo.keys()\n",
    "\n",
    "# create a general event dictionary with 2D array (charge,time) as values\n",
    "event = {} \n",
    "all_dom_keys = []\n",
    "for i in geo.omgeo.keys():\n",
    "    if i.pmt==0 and i.string <87:\n",
    "        all_dom_keys.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/data/user/fhenningsen/deepcore_data/felix_sca-domeff-11/PARAMS.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6f7871b5f199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get simulation set parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PARAMS.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpocams\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pocams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpocam_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pocam_keys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/icecube.opensciencegrid.org/py2-v3.1.1/RHEL_7_x86_64/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/data/user/fhenningsen/deepcore_data/felix_sca-domeff-11/PARAMS.npy'"
     ]
    }
   ],
   "source": [
    "# get simulation set parameters\n",
    "params = np.load(os.path.join(data_dir, 'PARAMS.npy')).item()\n",
    "\n",
    "pocams     = params['pocams']\n",
    "pocam_keys = params['pocam_keys']\n",
    "truth_arr  = params['truth_arr']\n",
    "truth_str  = params['truth_string']\n",
    "truth_dict = params['truth_dict']\n",
    "scan_N     = params['scan_N']\n",
    "scan_abs   = params['scan_abs']\n",
    "scan_sca   = params['scan_sca']\n",
    "scan_dome  = params['scan_domeff']\n",
    "scan_p0    = params['scan_p0']\n",
    "scan_p1    = params['scan_p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_string(abs_i, sca_i, dome_i, p0_i, p1_i):\n",
    "    p = 'ABS-%.3f_SCA-%.3f_DOME-%.3f_P0-%.3f_P1-%.3f' %(abs_i, sca_i, dome_i, p0_i, p1_i)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binned = h5py.File(data_dir + 'all_data.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data_binned['truth'].keys()\n",
    "dd = data_binned['data'].keys()\n",
    "\n",
    "for pk in pocams:\n",
    "    if pk in dt and pk in dd:\n",
    "        print('POCAM_KEY (%s) \\tavailable in TRUTH and SIM.' %pk)\n",
    "    else:\n",
    "        print('%s \\tMISSING !!!' %pk)\n",
    "\n",
    "print('\\nData structure:')\n",
    "print('\\tdata [TRUTH] [POCAM_KEY] [OM_KEY]')\n",
    "print('\\tdata [DATA]  [POCAM_KEY] [OM_KEY] [PARAM_STRING]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot an example time profile from truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk  = '88-72'\n",
    "ok  = '36-30-0'#OMKey(36,30,0)\n",
    "\n",
    "test_truth = data_binned['truth'][pk][ok][:]\n",
    "test_data  = data_binned['data'][pk][ok][param_string(1,1,0.9,1,1)][:]\n",
    "\n",
    "# raw time profiles\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.step(range(len(test_truth)), test_truth, where='mid', label='Truth')\n",
    "plt.step(range(len(test_data)), test_data, where='mid', color='red', label='Example data, DomEff = 0.9')\n",
    "plt.xlim(0, 1500)\n",
    "plt.xlabel('Time [ns]')\n",
    "plt.ylabel('Hits / bin')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# ratio\n",
    "plt.figure(figsize=(8,3))\n",
    "h = test_truth / test_data\n",
    "plt.hist(h[h>0], label='Truth / Data', range=(1, 10), bins=10)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the LLH-landsape\n",
    "For the likelihhod we combine the likelihoods of individual DOMs of all POCAM flashes. To keep it managable we only look at DOMs that are within a 100m radius around the corresponing POCAM. \n",
    "<br>\n",
    "Using the likelihood:\n",
    "$$\n",
    "\\mathcal{L} = \\prod_{\\text{POCAMs}} \\, \\prod_{\\text{DOMs} < 100m} \\, \\prod_{\\text{datapoints}} \\, p(d_i, t_i)\n",
    "$$\n",
    "using the log llh:\n",
    "$$\n",
    "-2 ln \\mathcal{L} = -2 \\sum_{\\text{POCAMs}} \\, \\sum_{\\text{DOMs} < 100m} \\, \\sum_{\\text{datapoints}} \\, ln( p(d_i, t_i))\n",
    "$$\n",
    "If $t_i$ > 20:\n",
    "$$\n",
    "p(d_i,t_i) = Normal(d_i,t_i) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\, e^{-\\frac{(d_i-t_i)^2}{2 \\sigma^2}} \\qquad \\text{where} \\quad \\sigma^2 = \\sqrt{t_i}^2 = t_i\n",
    "$$\n",
    "and if $t_i$ < 20:\n",
    "$$\n",
    "        p(d_i,t_i) = Poisson(d_i,t_i) = \\frac{t_i^{d_i}}{d_i !} \\, e^{-t_i} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pocams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define empty llh-landscape:\n",
    "llh_array = np.zeros((len(scan_sca),len(scan_dome)))\n",
    "\n",
    "# number of bins to use for llh (from first non-zero value)\n",
    "n_data = 25\n",
    "\n",
    "for sca_i, SCA in enumerate(scan_sca):\n",
    "    \n",
    "    for dome_i, DOME in enumerate(scan_dome):\n",
    "        \n",
    "        # parameter string (abs, sca, domeff, p0, p1)\n",
    "        par = param_string(truth_dict['abs'], SCA, DOME, truth_dict['p0'], truth_dict['p1'])\n",
    "        \n",
    "        # list of llh for pocams\n",
    "        llh_pocam = []\n",
    "        \n",
    "        for pocamk in pocam_keys:\n",
    "            \n",
    "            pk = '%i-%i' %(pocamk[0], pocamk[1])\n",
    "            print('Calculating %s' %(pk))\n",
    "            \n",
    "            # list of llh for doms\n",
    "            llh_doms = []\n",
    "            \n",
    "            # get POCAM coordinates:\n",
    "            p_x = geo.omgeo[pocamk].position.x\n",
    "            p_y = geo.omgeo[pocamk].position.y\n",
    "            p_z = geo.omgeo[pocamk].position.z\n",
    "            \n",
    "            for ok in all_dom_keys:\n",
    "                if ok.pmt == 0: # ignore upgrade OMs\n",
    "\n",
    "                    #list of llh for datapoints\n",
    "                    llh_datapoints = []\n",
    "                        \n",
    "                    # get DOM coordinates:\n",
    "                    d_x = geo.omgeo[ok].position.x\n",
    "                    d_y = geo.omgeo[ok].position.y\n",
    "                    d_z = geo.omgeo[ok].position.z\n",
    "\n",
    "                    # get distance to POCAM\n",
    "                    distance = np.sqrt((d_x-p_x)**2 + (d_y-p_y)**2 + (d_z-p_z)**2)\n",
    "                    \n",
    "                    # get h5 domkey\n",
    "                    omk = '%i-%i-%i' %(ok[0], ok[1], ok[2])\n",
    "                    \n",
    "                    # check if dom was hit at all\n",
    "                    v_truth = max(data_binned['truth'][pk][omk]) > 0\n",
    "                    v_sim   = max(data_binned['data'][pk][omk][par]) > 0\n",
    "                    \n",
    "#                     print(round(d_x,1), round(d_y,1), round(d_z,1))\n",
    "#                     print(round(p_x,1), round(p_y,1), round(p_z,1))\n",
    "#                     print(pk, ok, v_truth, v_sim, distance)\n",
    "#                     print('\\n')\n",
    "                    \n",
    "                    # look only at doms < 100m distance that were hit\n",
    "                    if v_truth and v_sim:\n",
    "                        \n",
    "                        truth    = data_binned['truth'][pk][omk]\n",
    "                        data_sim = data_binned['data'][pk][omk][par]\n",
    "                        \n",
    "                        # get first 20 datapoints:\n",
    "                        index = next((i for i, x in enumerate(truth) if x), None) # get index of first non-zero bin\n",
    "                        \n",
    "                        truth    = truth[index:index+n_data]\n",
    "                        data_sim = data_sim[index:index+n_data]\n",
    "\n",
    "                        for i in range(n_data):\n",
    "                            t = float(truth[i])\n",
    "                            d = float(data_sim[i])\n",
    "\n",
    "\n",
    "                            if t > 0:\n",
    "                                # use poisson if d <20. Values greater 20 cant be computed\n",
    "                                if d < 20.:\n",
    "                                    llh_datapoints.append( -2*( d*np.log(t) -np.log(np.math.factorial(d)) -t ) )\n",
    "\n",
    "                                # use gaussian:\n",
    "                                else:\n",
    "                                    llh_datapoints.append( (((d-t)**2)/t)+ 2*np.log((np.sqrt(2*np.pi*t)))  )\n",
    "                        \n",
    "                        \n",
    "                # append llh sum from DOM:\n",
    "                llh_doms.append(sum(llh_datapoints)/n_data)\n",
    "                        \n",
    "            # append llh sum from POCAM:\n",
    "            llh_pocam.append(sum(llh_doms))\n",
    "        \n",
    "        # putting the final llh into the landscape array:\n",
    "        llh_array[sca_i,dome_i]=sum(llh_pocam)\n",
    "\n",
    "print llh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax  = fig.add_subplot(111)\n",
    "\n",
    "# plot likelihood array\n",
    "x  = scan_dome\n",
    "y  = scan_sca\n",
    "dx = np.abs((np.unique(x)[1:] - np.unique(x)[:-1])/2)[0]\n",
    "dy = np.abs((np.unique(y)[1:] - np.unique(y)[:-1])/2)[0]\n",
    "xx = np.unique(np.append(x - dx, sorted(x + dx)[-1]))\n",
    "yy = np.unique(np.append(y - dy, sorted(y + dy)[-1]))\n",
    "plt.pcolormesh(xx, yy, llh_array)\n",
    "cbar = plt.colorbar(orientation='vertical',fraction=0.045,ax=ax)\n",
    "cbar.set_label(r'$-2 \\, ln \\, \\mathcal{L}$',fontsize=18)\n",
    "\n",
    "# plot markers for truth and min\n",
    "index_1,index_2=np.where(llh_array == np.amin(llh_array))\n",
    "plt.scatter(truth_dict['dome'], truth_dict['sca'], s=250,label='MC truth',marker='*', color='red')\n",
    "plt.scatter([scan_sca[int(index_1)]], [scan_dome[int(index_2)]], s=75,label='LLH min',marker='*', color='cyan')\n",
    "\n",
    "# format\n",
    "ax.set_title(\"Grid search\",fontsize=18)\n",
    "# ax.set_xticks(np.arange(0, len(scan_sca), 1))\n",
    "# ax.set_yticks(np.arange(0, len(scan_sca), 1))\n",
    "# ax.set_xticklabels(scan_sca)\n",
    "# ax.set_yticklabels(scan_dome)\n",
    "ax.set_xlabel('DomEff', fontsize=18)\n",
    "ax.set_ylabel('Sca', fontsize=18)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('grid_search.pdf')\n",
    "\n",
    "print \"LLH minimum at sca:\", scan_sca[int(index_1)]\n",
    "print \"        and domeff:\", scan_dome[int(index_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
